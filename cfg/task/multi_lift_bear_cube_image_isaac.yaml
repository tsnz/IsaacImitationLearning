name: multi_lift_bear_cube_image_isaac

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    agentview_image:
      shape: [3, 128, 128]
      type: rgb
    robot0_eef_image:
      shape: [3, 128, 128]
      type: rgb
    robot0_eef_pos:
      shape: [3]
      # type default: low_dim
    robot0_eef_quat:
      shape: [4]
    robot0_gripper_qpos:
      shape: [2]
  action: 
    shape: [7]

project: Multi-Lift-Bear-Cube
dataset_type: ph
dataset_path: &dataset_path /home/timo/master/datasets/vr_lift_combo_01/merged_lift_dataset_rgb_depth.hdf5
abs_action: &abs_action False
task_ids: &task_ids [IIL-Lift-Cube-v0, IIL-Lift-Teddy-v0]
topk:
  monitor_key: mean_score
  mode: max
  k: 3
  format_str: 'epoch={epoch:04d}-mean_score={mean_score:.3f}.ckpt'

env_runner:
  _target_: isaac_imitation_learning.robodiff.env_runner.isaac_lab_multi_env_image_runner.IsaacLabMultiEnvImageRunner
  env_wrapper:
    _partial_: True
    _target_: isaac_imitation_learning.robodiff.utils.isaac_lab_image_wrapper.IsaacLabImageWrapper
    env: null
    shape_meta: *shape_meta  
  isaac_args: ${isaac}
  task_ids: *task_ids
  n_test: 20
  n_test_vis: 3
  test_seed: 100000
  # use python's eval function as resolver, single-quoted string as argument
  max_steps: ${eval:'250 if "${task.dataset_type}" == "mh" else 200'}
  n_obs_steps: ${n_obs_steps}
  n_action_steps: ${n_action_steps}
  render_video: True
  render_obs_key: 'agentview_image'
  fps: 30
  crf: 22
  abs_action: *abs_action
  tqdm_interval_sec: 1.0
  n_envs: [10, 5]
  dummy_rollout: False  

dataset:
  _target_: diffusion_policy.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset
  shape_meta: *shape_meta
  dataset_path: *dataset_path
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1+${n_latency_steps}'}
  pad_after: ${eval:'${n_action_steps}-1'}
  n_obs_steps: ${dataset_obs_steps}
  abs_action: *abs_action
  rotation_rep: 'rotation_6d'
  use_legacy_normalizer: False
  use_cache: False
  seed: 42
  val_ratio: 0.02
